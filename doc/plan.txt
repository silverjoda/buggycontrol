Plan:

# Mission: Obtain High(er) performing buggy agent:
- Try with curriculum learning.
- Profile code using pycharm to speed up environment
- Use pretrained traj feature extractor from supervised learning? Transformer?

# Mission: Trajectory optimization using TEP
- Add positional encoding to Transformer
- Make trajectory inputs relative perhaps

# Mission: Transfer
- Make proper trajectory testing script with qualitative and quantitative metrics for comparing learned model with mujoco env (with visualization).
- Try dataset augmentation by using bilateral symmetry (Does the slow turning and forward velocity go away)
- Try balanced training (somehow)
- Implement meta learning for model learning
- Train RMA-style
- Compare RMA-style with trained model transfer
- Try RL with difficult initial state distribution predictor to help with difficult environments

# Results:
With deviation pen: Avg test rew: [33.278557], n_visited: 36.98 (12mln, 0.99 gamma, 0.0002 lr)
Without deviation pen: sux



