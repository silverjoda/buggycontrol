Plan:

Tuesday:
- Add possibility of including learned engine into mujoco env
- Experiment with using imit. trajectories in stable baselines rl
- Make new rs holder with straight and angled variant

Wednesday:
- Put rs holder to print
- Mount T265
- Gather large dataset for model learning
- Train model
- Train the rest
- Make new meat grinder ring which is taller

- See if feature processor (at least of given trajectory) from imitator can be used for RL,
compare RL performance with imitation. Is imitated agent (self supervised viable for this job).
- Learn NN odometry from data (predict lin. acc and ang. vel)
    . See if various data balancing techniques help with learning
- Fit mujoco simulation to data
- Make visual comparison of fitted Mujoco and learned data engine and ground truth
- Compare policies learned on mujoco and learned engine on real platform
- Can we use learned model to optimize a trajectory (with geometrical constraints) slightly for faster time?
    . First try in simulation
    . If works in simulation, obtain a hokuyo and try on real platform

