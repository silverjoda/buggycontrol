Plan:

# Mission: Obtain High(er) performing buggy agent:
- Try with curriculum learning.
- Optimize RL parameters using optuna
- Profile code using pycharm to speed up environment
- Use pretrained traj feature extractor from supervised learning? Transformer?

# Mission: Transfer
- Make proper trajectory testing script with qualitative and quantitative metrics for comparing learned model with mujoco env (with visualization).
- Try dataset augmentation by using bilateral symmetry (Does the slow turning and forward velocity go away)
- Try balanced training (somehow)
- Implement meta learning for model learning
- Train RMA-style
- Compare RMA-style with trained model transfer
- Try RL with difficult initial state distribution predictor to help with difficult environments

# Mission: Trajectory optimization using TEP
- Write training script for MLP and Transformer TEP from long trajectory


